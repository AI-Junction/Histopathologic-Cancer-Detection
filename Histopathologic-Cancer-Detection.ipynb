{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Junction/Histopathologic-Cancer-Detection/blob/master/Histopathologic-Cancer-Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0NoF022TreRu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check memory allocation to this sesssion"
      ]
    },
    {
      "metadata": {
        "id": "HiC2mY5E57ad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "530cd3f2-73d8-4178-eb34-7b933ba6ba74"
      },
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         359G   18G  323G   6% /\n",
            "tmpfs           6.4G     0  6.4G   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "tmpfs           6.4G  8.0K  6.4G   1% /var/colab\n",
            "/dev/sda1       365G   22G  344G   6% /opt/bin\n",
            "shm             6.0G     0  6.0G   0% /dev/shm\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTGfs5-Q27X_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "id": "BN9O5cVk2uJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f730f73-e13e-484a-923a-76f80da3ae31"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o40Dy-h431QS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check RAM allocation in current session"
      ]
    },
    {
      "metadata": {
        "id": "dm9C91QJ30RX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "fb69baca-6441-482d-ff78-0a1392e18ff9"
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.5 GB  | Proc size: 692.8 MB\n",
            "GPU RAM Free: 11325MB | Used: 116MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-PFAjmv2yzZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "**** Uncomment below cell if needed"
      ]
    },
    {
      "metadata": {
        "id": "bzbVk-cP2x9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7e8b2189-8406-419d-ff1b-157b85bb1c76"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()\n",
        "\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nimport tensorflow as tf\\nimport timeit\\n\\n# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\\nconfig = tf.ConfigProto()\\nconfig.gpu_options.allow_growth = True\\n\\nwith tf.device(\\'/cpu:0\\'):\\n  random_image_cpu = tf.random_normal((100, 100, 100, 3))\\n  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\\n  net_cpu = tf.reduce_sum(net_cpu)\\n\\nwith tf.device(\\'/gpu:0\\'):\\n  random_image_gpu = tf.random_normal((100, 100, 100, 3))\\n  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\\n  net_gpu = tf.reduce_sum(net_gpu)\\n\\nsess = tf.Session(config=config)\\n\\n# Test execution once to detect errors early.\\ntry:\\n  sess.run(tf.global_variables_initializer())\\nexcept tf.errors.InvalidArgumentError:\\n  print(\\n      \\'\\n\\nThis error most likely means that this notebook is not \\'\\n      \\'configured to use a GPU.  Change this in Notebook Settings via the \\'\\n      \\'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n\\')\\n  raise\\n\\ndef cpu():\\n  sess.run(net_cpu)\\n  \\ndef gpu():\\n  sess.run(net_gpu)\\n  \\n# Runs the op several times.\\nprint(\\'Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images \\'\\n      \\'(batch x height x width x channel). Sum of ten runs.\\')\\nprint(\\'CPU (s):\\')\\ncpu_time = timeit.timeit(\\'cpu()\\', number=10, setup=\"from __main__ import cpu\")\\nprint(cpu_time)\\nprint(\\'GPU (s):\\')\\ngpu_time = timeit.timeit(\\'gpu()\\', number=10, setup=\"from __main__ import gpu\")\\nprint(gpu_time)\\nprint(\\'GPU speedup over CPU: {}x\\'.format(int(cpu_time/gpu_time)))\\n\\nsess.close()\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "JQ5kplL6sbfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check total memory allocation\n",
        "\n",
        "*** Uncomment below cell only if needed"
      ]
    },
    {
      "metadata": {
        "id": "kcFqYxzH9z7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWOpFaOIsl6T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check versions of various libraries installed in this session of colaboratory\n",
        "\n",
        "**** Uncomment below cell only if needed"
      ]
    },
    {
      "metadata": {
        "id": "HbIRMWHURzeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6aab8d6b-5b38-4d0a-8b58-f662a5c428bd"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
        "print(\"Python version: {}\". format(sys.version))\n",
        "\n",
        "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
        "print(\"pandas version: {}\". format(pd.__version__))\n",
        "\n",
        "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
        "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
        "\n",
        "import numpy as np #foundational package for scientific computing\n",
        "print(\"NumPy version: {}\". format(np.__version__))\n",
        "\n",
        "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
        "print(\"SciPy version: {}\". format(sp.__version__)) \n",
        "\n",
        "import IPython\n",
        "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
        "print(\"IPython version: {}\". format(IPython.__version__)) \n",
        "\n",
        "import sklearn #collection of machine learning algorithms\n",
        "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
        "\n",
        "#misc libraries\n",
        "import random\n",
        "import time\n",
        "\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". format(sys.version))\\n\\nimport pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\\nprint(\"pandas version: {}\". format(pd.__version__))\\n\\nimport matplotlib #collection of functions for scientific and publication-ready visualization\\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\\n\\nimport numpy as np #foundational package for scientific computing\\nprint(\"NumPy version: {}\". format(np.__version__))\\n\\nimport scipy as sp #collection of functions for scientific computing and advance mathematics\\nprint(\"SciPy version: {}\". format(sp.__version__)) \\n\\nimport IPython\\nfrom IPython import display #pretty printing of dataframes in Jupyter notebook\\nprint(\"IPython version: {}\". format(IPython.__version__)) \\n\\nimport sklearn #collection of machine learning algorithms\\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\\n\\n#misc libraries\\nimport random\\nimport time\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Kw8e1sxsWAYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d208dda1-a60d-45e8-af45-9c19881568aa"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "!git clone https://gist.github.com/dc7e60aa487430ea704a8cb3f2c5d6a6.git /tmp/colab_util_repo\n",
        "!mv /tmp/colab_util_repo/colab_util.py colab_util.py \n",
        "!rm -r /tmp/colab_util_repo"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/colab_util_repo'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40\u001b[K\n",
            "Unpacking objects:   2% (1/40)   \rUnpacking objects:   5% (2/40)   \rUnpacking objects:   7% (3/40)   \rUnpacking objects:  10% (4/40)   \rUnpacking objects:  12% (5/40)   \rUnpacking objects:  15% (6/40)   \rUnpacking objects:  17% (7/40)   \rUnpacking objects:  20% (8/40)   \rUnpacking objects:  22% (9/40)   \rUnpacking objects:  25% (10/40)   \rUnpacking objects:  27% (11/40)   \rUnpacking objects:  30% (12/40)   \rUnpacking objects:  32% (13/40)   \rUnpacking objects:  35% (14/40)   \rUnpacking objects:  37% (15/40)   \rUnpacking objects:  40% (16/40)   \rUnpacking objects:  42% (17/40)   \rUnpacking objects:  45% (18/40)   \rUnpacking objects:  47% (19/40)   \rUnpacking objects:  50% (20/40)   \rUnpacking objects:  52% (21/40)   \rUnpacking objects:  55% (22/40)   \rUnpacking objects:  57% (23/40)   \rUnpacking objects:  60% (24/40)   \rUnpacking objects:  62% (25/40)   \rUnpacking objects:  65% (26/40)   \rUnpacking objects:  67% (27/40)   \rUnpacking objects:  70% (28/40)   \rUnpacking objects:  72% (29/40)   \rUnpacking objects:  75% (30/40)   \rUnpacking objects:  77% (31/40)   \rUnpacking objects:  80% (32/40)   \rUnpacking objects:  82% (33/40)   \rUnpacking objects:  85% (34/40)   \rUnpacking objects:  87% (35/40)   \rUnpacking objects:  90% (36/40)   \rUnpacking objects:  92% (37/40)   \rUnpacking objects:  95% (38/40)   \rUnpacking objects:  97% (39/40)   \rUnpacking objects: 100% (40/40)   \rUnpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjBOuMRy3gnP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!ls -l /tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A7hM__AsVyTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from colab_util import *\n",
        "drive_handler = GoogleDriveHandler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dUz-iLKIitkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "27944735-ea8b-4f54-cf8c-b5a624ad659c"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4JRbSL-ToWIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "De3f_YB8obZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cdfdaa6-2912-4e67-fa04-19c0a5ef9f1b"
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "#filename = \"/content/.kaggle/kaggle.json\"\n",
        "#filename = \"/.kaggle/kaggle.json\"\n",
        "filename = \"kaggle.json\"\n",
        "#os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QJZsCT4o3A5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57cb439a-8957-488c-fdf9-ad08cbaaeee9"
      },
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---x-wx--T 1 root root 65 Dec 22 10:41 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yxb8N3E3o8FN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b11f13f8-bee3-4f9e-e61c-017e203449ab"
      },
      "cell_type": "code",
      "source": [
        "os.path.isdir(\"/root/.kaggle\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "9uUUcDqhpAuJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb4b3cb5-3c55-47e9-8ea4-47833a540e4b"
      },
      "cell_type": "code",
      "source": [
        "dir_kaggle = \"/root/.kaggle\"\n",
        "if not os.path.isdir(dir_kaggle):\n",
        "  !mkdir -p ~/.kaggle  \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "os.path.isdir(dir_kaggle)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "_ErgTi5tpFFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IS_LrIG9B-v5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create training and test data in this allocated session of colaboratory"
      ]
    },
    {
      "metadata": {
        "id": "eBXyjtrhB-QX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir '/content/Histopathologic-Cancer-Detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1rk6WHL0CGfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('/content/Histopathologic-Cancer-Detection/test'):\n",
        "  !mkdir '/content/Histopathologic-Cancer-Detection/test'\n",
        "  \n",
        "if not os.path.isdir('/content/Histopathologic-Cancer-Detection/train'):\n",
        "  !mkdir '/content/Histopathologic-Cancer-Detection/train'  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYh3dkXAFRzA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To copy file into colab from GCD"
      ]
    },
    {
      "metadata": {
        "id": "6UZhjDONCOWw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile('/content/Histopathologic-Cancer-Detection/test.zip'):\n",
        "  !cp '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/test.zip' '/content/Histopathologic-Cancer-Detection'\n",
        "else:\n",
        "  print('file exists')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KkNdgVAFCxwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "701dd9e9-7a0c-4558-acb0-2a78cc5407f9"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "HCDBaseDirTestDir_files = sorted(glob.glob('/content/Histopathologic-Cancer-Detection/test/*'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in HCDBaseDirTestDir_files]\n",
        "print(len(archived_files))\n",
        "if len(archived_files) == 0:\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/test.zip\" -d \"/content/Histopathologic-Cancer-Detection/test/\"\n",
        "else:\n",
        "  print('already unzipped')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57458\n",
            "already unzipped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HlccqHaQpZJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "71e6d83b-b041-455c-c6d1-d729e76c0896"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions files -c histopathologic-cancer-detection"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name                   size  creationDate         \n",
            "---------------------  ----  -------------------  \n",
            "sample_submission.csv   2MB  2018-11-15 23:20:36  \n",
            "train_labels.csv        9MB  2018-11-15 23:20:37  \n",
            "test.zip                1GB  2018-11-15 23:21:06  \n",
            "train.zip               5GB  2018-11-15 23:23:49  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eDE--qt0FLUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i17v-gxzOiFF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download competition files to colab folders"
      ]
    },
    {
      "metadata": {
        "id": "VofS_vnzs5ZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8650bf75-939f-4120-b945-95312d5e0a3f"
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"/content/Histopathologic-Cancer-Detection/train_labels.csv.zip\"):\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f sample_submission.csv -p \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f train_labels.csv -p \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f test.zip -p \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f train.zip -p \"/content/Histopathologic-Cancer-Detection/\"\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sample_submission.csv.zip to /content/Histopathologic-Cancer-Detection\n",
            "\r  0% 0.00/1.33M [00:00<?, ?B/s]\n",
            "100% 1.33M/1.33M [00:00<00:00, 44.2MB/s]\n",
            "Downloading train_labels.csv.zip to /content/Histopathologic-Cancer-Detection\n",
            "  0% 0.00/5.10M [00:00<?, ?B/s]\n",
            "100% 5.10M/5.10M [00:00<00:00, 46.9MB/s]\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading train.zip to /content/Histopathologic-Cancer-Detection\n",
            "100% 4.97G/4.98G [00:37<00:00, 134MB/s]\n",
            "100% 4.98G/4.98G [00:37<00:00, 142MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kbl9P1_EP4E1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "902eade6-deae-4060-a2d2-f11ff5f6dacb"
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"/content/Histopathologic-Cancer-Detection/train_labels.csv\"):\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/train_labels.csv.zip\" -d \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  \n",
        "if not os.path.isfile(\"/content/Histopathologic-Cancer-Detection/sample_submission.csv\"):\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/sample_submission.csv.zip\" -d \"/content/Histopathologic-Cancer-Detection/\"  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Histopathologic-Cancer-Detection/train_labels.csv.zip\n",
            "  inflating: /content/Histopathologic-Cancer-Detection/train_labels.csv  \n",
            "Archive:  /content/Histopathologic-Cancer-Detection/sample_submission.csv.zip\n",
            "  inflating: /content/Histopathologic-Cancer-Detection/sample_submission.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C5-bdIevPrSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b3e441a4-0869-467b-eab8-57b38b458faa"
      },
      "cell_type": "code",
      "source": [
        "HCDTrainDir_files = sorted(glob.glob('/content/Histopathologic-Cancer-Detection/train/*'))\n",
        "archived_files = 0\n",
        "archived_files = [f for f in HCDTrainDir_files]\n",
        "print(len(archived_files))\n",
        "if len(archived_files) == 0:\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/train.zip\" -d \"/content/Histopathologic-Cancer-Detection/train/\"\n",
        "else:\n",
        "  print('already unzipped')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "220025\n",
            "already unzipped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-XaIGdZrxQcf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv\"):\n",
        "  !unzip \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv.zip\" -d \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGaa5VPSlzmy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UyhP6hulGkQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GoogleDriveHandler?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w_fGiy0QHFQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gcd_ID = drive_handler.path_to_id('/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/')\n",
        "gcd_ID\n",
        "#drive_handler.list_folder(gcd_ID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2Nwr2htcioi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ce79d23-7015-49bf-c026-9169ccb88f9a"
      },
      "cell_type": "code",
      "source": [
        "os.path.isdir('/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir/train_dir/a_no_tumor_tissue/')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jQK6aofxs3q4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#import glob\n",
        "HCDBaseDirTrainDir_files = sorted(glob.glob('/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir/train_dir/a_no_tumor_tissue/*'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in HCDBaseDirTrainDir_files]\n",
        "print(len(archived_files))\n",
        "\n",
        "\n",
        "#for f in archived_files:\n",
        "#    print(f)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "erjV7py5szmR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!cp -r '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir' '/content/Histopathologic-Cancer-Detection/base_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IzaBFz80LBBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#tar_file_path = create_archive('HCDBaseDirTrainDir', local_file_paths=archived_files[:10], verbose=True)\n",
        "#tar_file_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZFSmB4BGtU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print([x for x in dir(GoogleDriveHandler)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eb1RH2COtRTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example of how to archive files in notebook"
      ]
    },
    {
      "metadata": {
        "id": "FaFEMFw2Y4mR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "ipynb_files = sorted(glob.glob('sample_data/*.csv'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in ipynb_files]\n",
        "for f in archived_files:\n",
        "    print(f)\n",
        "    \n",
        "'''    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcddNqKVZfuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tar_file_path = create_archive('sample_archive', local_file_paths=archived_files, verbose=True)\n",
        "#tar_file_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mNY-dRYAaMvH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!ls -l '/tmp/sample_archive.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1njth6sWtuYd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example of how to create folders in GCD using drive handler"
      ]
    },
    {
      "metadata": {
        "id": "NbtRPdTJWSlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_folder_id = drive_handler.create_folder('test_folder')\n",
        "test_folder_id\n",
        "\n",
        "test_subfolder_id = drive_handler.create_folder('test_sub_folder', parent_path='test_folder')\n",
        "test_subfolder_id\n",
        "\n",
        "same_subfolder_id = drive_handler.create_folder('test_sub_folder', parent_path='test_folder')\n",
        "test_subfolder_id\n",
        "\n",
        "same_subfolder_id2 = drive_handler.create_folder('test_sub_folder2', parent_path='test_folder')\n",
        "test_subsubfolder_id = drive_handler.create_folder('test_sub_sub_folder', parent_path='test_folder/test_sub_folder2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tAneW8j3uNMO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Examples of how to access list of files in a folder using drive handler"
      ]
    },
    {
      "metadata": {
        "id": "3quUhR4HW_fh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ID = drive_handler.path_to_id('test_folder/test_sub_folder2/test_sub_sub_folder')\n",
        "ID, test_subsubfolder_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-dtXQTssXLx7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive_handler.list_folder(test_folder_id)\n",
        "drive_handler.list_folder(test_folder_id, max_depth=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caem35IcuxuR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To upload file to GCD"
      ]
    },
    {
      "metadata": {
        "id": "lWsdFCaOXEO0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#drive_handler.upload(tar_file_path, parent_path='test_folder/test_sub_folder2')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZ1v1vJ_u6Ob",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To download file into Colab from GCD"
      ]
    },
    {
      "metadata": {
        "id": "PAsayaIzbc_-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#drive_handler.download('/tmp/downloaded_archive.tar.gz', target_path='test_folder/test_sub_folder2/sample_archive.tar.gz')\n",
        "#!ls -l '/tmp/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwrXvcWV9OA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ipynb_files = sorted(glob.glob('sample_data/*.csv'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in ipynb_files]\n",
        "for f in archived_files:\n",
        "    print(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7dgMvZ_Tguw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# 2. Create & upload a file text file.\n",
        "uploaded = drive.CreateFile({'title': 'Sample upload.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "downloaded = drive.CreateFile({'id': uploaded.get('id')})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uzKQbD_8ULoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls -l \"/root\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pvRMek_pHZy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pT2OjMjYiKYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.path.isdir(\"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2MDUYFRkiS6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.path.isfile(\"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l_SRjIffiokp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.path.isdir(\"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmEXjKP5r5hj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(\"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection\"):\n",
        "  ! mkdir -p \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qe9h_C06i2fx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "if not os.path.isdir(\"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/test\"):\n",
        "  !mkdir -p \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/test\"\n",
        "  !unzip \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/test.zip\" -d \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/test\"\n",
        "'''  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mcs11Y2hj2ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(101)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(101)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgoq9Msnj7RU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 96\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "SAMPLE_SIZE = 10000 # the number of images we use from each of the two classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOQMBb0nj_Re",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.listdir('drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3_bDT2HlV2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.path.isfile('drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9uxNwsTmec9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!chmod 600 'drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8YSBi-STmV4V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls -l 'drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdJrIJy9kWRY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data = pd.read_csv('drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv', engine='python')\n",
        "\n",
        "# removing this image because it caused a training error previously\n",
        "df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
        "\n",
        "# removing this image because it's black\n",
        "df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
        "\n",
        "\n",
        "print(df_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbJNi6N5nDNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5uyCG8j1n-a4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# source: https://www.kaggle.com/gpreda/honey-bee-subspecies-classification\n",
        "\n",
        "def draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n",
        "    \n",
        "    \"\"\"\n",
        "    Give a column in a dataframe,\n",
        "    this function takes a sample of each class and displays that\n",
        "    sample on one row. The sample size is the same as figure_cols which\n",
        "    is the number of columns in the figure.\n",
        "    Because this function takes a random sample, each time the function is run it\n",
        "    displays different images.\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    categories = (df.groupby([col_name])[col_name].nunique()).index\n",
        "    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n",
        "                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n",
        "    # draw a number of images for each location\n",
        "    for i, cat in enumerate(categories):\n",
        "        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n",
        "        for j in range(0,figure_cols):\n",
        "            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n",
        "            #print(file)\n",
        "            im=cv2.imread(file)\n",
        "            #print(im)\n",
        "            #print(im.shape)\n",
        "            ax[i, j].imshow(im, resample=True, cmap='gray')\n",
        "            ax[i, j].set_title(cat, fontsize=16)  \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0bifBiHqKln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "train_files = glob.glob('drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train/*')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hl5m69JbqjnD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(train_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_7FMp-9q-Zu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files = pd.DataFrame(train_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t315mZz4srsJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files.columns = ['filename']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vuUGJ5qhtIFl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files['tmp_col'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B3X26bPeuG3e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df_data_new = df_data.loc[df['id'].isin(df_train_files)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kf54NeY4rs7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df_train_files_tmp = df_train_files['filename'].split(\".\")\n",
        "\n",
        "df_train_files_tmp = pd.DataFrame(df_train_files['filename'].apply(lambda x: x.split('.',1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahqEMYmMze59",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files_tmp1 = [x[0] for x in df_train_files_tmp.filename[:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gWv1xmMs0RJn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files_tmp1[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pKyC1qVmEbEu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(type(df_train_files_tmp1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PU6wNdwuxL46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files_tmp2 = pd.DataFrame(df_train_files_tmp1) #.apply(lambda x: x.split('/',1))\n",
        "df_train_files_tmp2.columns = ['filename']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KzGTkLqmE_nx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(df_train_files_tmp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gyg5V339EoVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files_tmp3 = pd.DataFrame(df_train_files_tmp2['filename'].apply(lambda x: x.split('/',-1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJFPUeqLFMY2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files_tmp4 = [x[-1] for x in df_train_files_tmp3.filename[:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UeWmTuaAFjDz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_files_tmp4[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxdyryrSGEV3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data_new = df_data.loc[df_data['id'].isin(df_train_files_tmp4)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3-jEq0JHR5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data_new.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxupH8hnGO_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data_new.shape\n",
        "df_data_new.columns\n",
        "df_data_new.head()\n",
        "df_data_new.id[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jcSpXfFlHzNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data_new = df_data_new.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BIOALvxVplRK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.path.join('drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train', df_data_new.id[10]+'.tif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IGBHalAdoCdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = 'drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train/' \n",
        "\n",
        "draw_category_images('label',3, df_data_new, IMAGE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bsDwD-6tVP2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(SAMPLE_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8hDe9nr6-BY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# take a random sample of class 0 with size equal to num samples in class 1\n",
        "df_0 = df_data_new[df_data_new['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
        "# filter out class 1\n",
        "df_1 = df_data_new[df_data_new['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
        "\n",
        "# concat the dataframes\n",
        "df_data_new = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
        "# shuffle\n",
        "df_data_new = shuffle(df_data_new)\n",
        "\n",
        "df_data_new['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GYfLQRuCVqU4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_test_split\n",
        "\n",
        "# stratify=y creates a balanced validation set.\n",
        "y = df_data_new['label']\n",
        "\n",
        "df_train, df_val = train_test_split(df_data_new, test_size=0.10, random_state=101, stratify=y)\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AVFwHQv6Vz_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uABPJFW4V5YX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_val['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYXXqRre_wpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_dir = 'drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWCUMICRWchm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Create a new directory\n",
        "base_dir = 'drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir'\n",
        "os.mkdir(base_dir)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhBFYTuDV6-g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
        "\n",
        "# now we create 2 folders inside 'base_dir':\n",
        "\n",
        "# train_dir\n",
        "    # a_no_tumor_tissue\n",
        "    # b_has_tumor_tissue\n",
        "\n",
        "# val_dir\n",
        "    # a_no_tumor_tissue\n",
        "    # b_has_tumor_tissue\n",
        "\n",
        "\n",
        "\n",
        "# create a path to 'base_dir' to which we will join the names of the new folders\n",
        "# train_dir\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "\n",
        "\n",
        "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
        "# Inside each folder we create seperate folders for each class\n",
        "\n",
        "# create new folders inside train_dir\n",
        "no_tumor_tissue = os.path.join(train_dir, 'a_no_tumor_tissue')\n",
        "os.mkdir(no_tumor_tissue)\n",
        "has_tumor_tissue = os.path.join(train_dir, 'b_has_tumor_tissue')\n",
        "os.mkdir(has_tumor_tissue)\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "no_tumor_tissue = os.path.join(val_dir, 'a_no_tumor_tissue')\n",
        "os.mkdir(no_tumor_tissue)\n",
        "has_tumor_tissue = os.path.join(val_dir, 'b_has_tumor_tissue')\n",
        "os.mkdir(has_tumor_tissue)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "thPPqJ4KWsyb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "# check that the folders have been created\n",
        "os.listdir(base_dir + '/train_dir')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qn5p2k_raF8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Set the id as the index in df_data\n",
        "df_data_new.set_index('id', inplace=True)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UjULcyeBaVxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Get a list of train and val images\n",
        "train_list = list(df_train['id'])\n",
        "val_list = list(df_val['id'])\n",
        "\n",
        "train_src_dir = 'drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train'\n",
        "\n",
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image + '.tif'\n",
        "    # get the label for a certain image\n",
        "    target = df_data_new.loc[image,'label']\n",
        "    \n",
        "    # these must match the folder names\n",
        "    if target == 0:\n",
        "        label = 'a_no_tumor_tissue'\n",
        "    if target == 1:\n",
        "        label = 'b_has_tumor_tissue'\n",
        "    \n",
        "    # source path to image\n",
        "    src = os.path.join(train_src_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(train_dir, label, fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image + '.tif'\n",
        "    # get the label for a certain image\n",
        "    target = df_data_new.loc[image,'label']\n",
        "    \n",
        "    # these must match the folder names\n",
        "    if target == 0:\n",
        "        label = 'a_no_tumor_tissue'\n",
        "    if target == 1:\n",
        "        label = 'b_has_tumor_tissue'\n",
        "    \n",
        "\n",
        "    # source path to image\n",
        "    src = os.path.join(train_src_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(val_dir, label, fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "\n",
        "'''\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_C7zYgkb11-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(os.path.join(base_dir, 'train_dir','a_no_tumor_tissue'))))\n",
        "print(len(os.listdir(os.path.join(base_dir, 'train_dir','b_has_tumor_tissue'))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4ZkoZ8H_Tib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(os.path.join(base_dir, 'val_dir','a_no_tumor_tissue'))))\n",
        "print(len(os.listdir(os.path.join(base_dir, 'val_dir','b_has_tumor_tissue'))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qwPoEeSUAaDo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path = base_dir + '/train_dir'\n",
        "valid_path = base_dir + '/val_dir'\n",
        "test_path = '../input/test'\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
        "\n",
        "print(num_train_samples)\n",
        "print(num_val_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrE6zgoeBAmn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ibYt8xuyBPWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size)) \n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJjiHWcYB8RW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W8mnvhfCGOA3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(val_gen.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zAelgNqtGQAs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
        "                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "                              \n",
        "                              \n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=20, verbose=1,\n",
        "                   callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "teTTTnip-Czw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}